```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
There are 3-4 packages you will need to install for today's practical: `install.packages(c("xgboost", "eegkit", "forecast", "tseries", "caret"))` apart from that everything else should already be available on your system. 

If you are using a newer Mac you may have to also install [quartz](https://www.xquartz.org/) to have everything work (do this if you see errors about `X11` during install/execution).

I will endeavour to use explicit imports to make it clear where functions are coming from (functions without `library_name::` are part of base R or a function we've defined in this notebook).

```{r libraries, echo=FALSE}
# Using the same library we used earlier in the course for tabular data because we know it works!
library(xgboost)

# EEG manipulation library in R (although very limited compared to signal processing libraries available in other languages, matlab might actually still be a leader in this specific area)
library(eegkit)

# some time series functions (that we only skim the depths of)
library(forecast)
library(tseries)
library(caret)

# just tidyverse libraries that should already be installed
library(dplyr)
library(reshape2)
library(purrr)
library(ggplot2)
```

## EEG Eye Detection Data

One of the most common types of medical sensor data (and one that we talked about during the lecture) are Electroencephalograms (EEGs).  
These measure mesoscale electrical signals (measured in microvolts) within the brain, which are indicative of a region of neuronal activity.
Typically, EEGs involve an array of sensors (aka channels) placed on the scalp with a high degree of covariance between sensors.

As EEG data can be very large and unwieldy, we are going to use a relatively small/simple dataset today from [this paper](http://ehrai.com/su/pdf/aihls2013.pdf).

This dataset is a 117 second continuous EEG measurement collected from a single person with a device called a "Emotiv EEG Neuroheadset".
In combination with the EEG data collection, a camera was used to record whether person being recorded had their eyes open or closed. 
This was eye status was then manually annotated onto the EEG data with `1` indicated the eyes being closed and `0` the eyes being open.
Measures microvoltages are listed in chronological order with the first measured value at the top of the dataframe.

Let's parse the data directly from the `h2o` library's (which we aren't actually using directly) test data S3 bucket:

```{r parse_data}
eeg_url <- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate_splits.csv"
eeg_data <- read.csv(eeg_url)

# add timestamp
Fs <- 117 / nrow(eeg_data)
eeg_data <- transform(eeg_data, ds = seq(0, 116.99999, by = Fs), eyeDetection = as.factor(eyeDetection))
print(table(eeg_data$eyeDetection))
```

```{r}
# split dataset into train, validate, test
eeg_train <- subset(eeg_data, split == 'train', select = -split)
print(table(eeg_train$eyeDetection))
```

```{r}
eeg_validate <- subset(eeg_data, split == 'valid', select = -split)
eeg_test <- subset(eeg_data, split == 'test', select = -split)
```

**0** Knowing the `eeg_data` contains 117 seconds of data, inspect the `eeg_data` dataframe and the code above to and determine how many samples per second were taken?       
**Since it's 117 seconds, and the numbers of the sample is 14,980 (8,257+ 6,723). So, the number of the sample per second = 14,980 / 117 = 128.03**

**1** How many EEG electrodes/sensors were used?      
**As coding shown below, the number of EEG electrodes/sensors were used is 15**
```{r}
# get the number 
num_electrodes <- ncol(eeg_data) - 2  # - eye Detection and ds coloum 
num_electrodes
```

### Exploratory Data Analysis

Now that we have the dataset and some basic parameters let's begin with the ever important/relevant exploratory data analysis.

First we should check there is no missing data!
```{r check_na}
sum(is.na(eeg_data))
```

Great, now we can start generating some plots to look at this data within the time-domain.

First we use `reshape2::melt()` to transform the `eeg_data` dataset from a wide format to a long format expected by `ggplot2`.

Specifically, this converts from "wide" where each electrode has its own column, to a "long" format, where each observation has its own row. 
This format is often more convenient for data analysis and visualization, especially when dealing with repeated measurements or time-series data.

We then use `ggplot2` to create a line plot of electrode intensities per sampling time, with the lines coloured by electrode, and the eye status annotated using dark grey blocks.

```{r plot_data}
melt <- reshape2::melt(eeg_data %>% dplyr::select(-split), id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")


ggplot2::ggplot(melt, ggplot2::aes(x=ds, y=microvolts, color=Electrode)) + 
  ggplot2::geom_line() + 
  ggplot2::ylim(3500,5000) + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(melt, eyeDetection==1), alpha=0.005)
```

**2** Do you see any obvious patterns between eyes being open (dark grey blocks in the plot) and the EEG intensities?       
**First of all, in the provided plot, the dark grey blocks is the periods when the eyes are open (eyeDetection = 1).    
So we can see some patterns.     
Dark Grey Blocks(When Eyes are Open):Signal Stability: Many electrodes exhibit relatively stable EEG signal intensities when the eyes are open. The fluctuations are smaller, and the changes are more gradual. Intensity Changes: While the signals are generally stable, some electrodes (such as T7 and P7) show a slight increase in signal intensity when the eyes are open.     
White Blocks (When Eyes are Closed): Signal Fluctuations: In contrast, when the eyes are closed, many electrodes show larger fluctuations and more noticeable changes in EEG signal intensities. The signals exhibit more pronounced peaks and valleys. Significant Changes: Certain electrodes (such as AF3 and F7) display significant changes in signal intensity when the eyes are closed, with some showing substantial variations in amplitude. This might be related to the brain entering different states of activity, such as relaxation or preparing for sleep.**

**3** Similarly, based on the distribution of eye open/close state over time to anticipate any temporal correlation between these states?     
**By analyzing the distribution of eye open and close states over time, we can identify potential temporal correlations between these states. This correlation can help us predict future eye states. For example, if we know that the eye state switches every certain period, we can predict future states based on the current state.    
Overall, through time series analysis and correlation checks, we can better understand the temporal patterns of eye states and use these patterns for prediction. This has significant implications for further neuroscience research and practical applications.**

Let's see if we can directly look at the distribution of EEG intensities and see how they related to eye status.


As there are a few extreme outliers in voltage we will use the `dplyr::filter` function to remove values outwith of 3750 to 50003. The function uses the `%in%` operator to check if each value of microvolts is within that range. The function also uses the `dplyr::mutate()` to change the type of the variable eyeDetection from numeric to a factor (R's categorical variable type).

```{r compare_distrib}
melt_train <- reshape2::melt(eeg_train, id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")

# filter huge outliers in voltage
filt_melt_train <- dplyr::filter(melt_train, microvolts %in% (3750:5000)) %>% dplyr::mutate(eyeDetection=as.factor(eyeDetection))

ggplot2::ggplot(filt_melt_train, ggplot2::aes(y=Electrode, x=microvolts, fill=eyeDetection)) + ggplot2::geom_boxplot()
```



Plots are great but sometimes so it is also useful to directly look at the summary statistics and how they related to eye status.
We will do this by grouping the data based on eye status and electrode before calculating the statistics using the convenient `dplyr::summarise` function.

```{r compare_summary_stats}
filt_melt_train %>% dplyr::group_by(eyeDetection, Electrode) %>% 
    dplyr::summarise(mean = mean(microvolts), median=median(microvolts), sd=sd(microvolts)) %>% 
    dplyr::arrange(Electrode)
```




**4** Based on these analyses are any electrodes consistently more intense or varied when eyes are open?    
**1. Electrode AF3:   
Eyes Closed (0): Mean = 4294.4, Median = 4300, SD = 35.4     
Eyes Open (1): Mean = 4305.4, Median = 4300, SD = 34.4     
Observation: The mean and median values are slightly higher when the eyes are open, but the standard deviation is slightly lower. This indicates a marginal increase in intensity but slightly less variability.     
Electrode F7:     
Eyes Closed (0): Mean = 4015.4, Median = 4020, SD = 28.4    
Eyes Open (1): Mean = 4007.4, Median = 4000, SD = 24.9    
Observation: Both the mean and median values are slightly lower when the eyes are open, and there is a reduction in variability. This suggests less intensity and variation when the eyes are open.    
Electrode F3:    
Eyes Closed (0): Mean = 4268.4, Median = 4260, SD = 20.9    
Eyes Open (1): Mean = 4269.4, Median = 4260, SD = 17.4     
Observation: The mean and median values are nearly identical between the two states, but the standard deviation is lower when the eyes are open. This implies that the variability decreases when the eyes are open.     
Electrode T7:     
Eyes Closed (0): Mean = 4341.4, Median = 4340, SD = 13.9     
Eyes Open (1): Mean = 4342.4, Median = 4340, SD = 15.5     
Observation: The mean and median values are almost the same for both states, but the variability increases slightly when the eyes are open.     
So，Electrodes AF3 and F3: Show slightly higher intensity and less variability when eyes are open. Electrode F7: Shows less intensity and variability when eyes are open. Electrode T7: Shows slightly more variability when eyes are open.**



#### Time-Related Trends

As it looks like there may be a temporal pattern in the data we should investigate how it changes over time.  

First we will do a statistical test for stationarity:

```{r convert_to_tseries}
apply(eeg_train, 2, tseries::adf.test)
```

 
**5** What is stationarity?         
**Stationarity is a concept concept from time series analysis. Specifically, a stationary time series should satisfy the following conditions:       
1. Constant Mean: The mean of the time series does not change over time.     
2. Constant Variance: The variance of the time series does not change over time.     
3. Constant Autocorrelation: The autocorrelation of the time series depends only on the lag between time points, not on the actual time points themselves.**



**6** Why are we interested in stationarity? What do the results of these tests tell us? (ignoring the lack of multiple comparison correction...)       
**Why are we interested in stationarity?     
Different Methods Selection:        
Analyzing non-stationary time series requires more complex preprocessing steps, such as differencing or detrending, while stationary time series can directly use many classic time series analysis methods (e.g., ARIMA models). This greatly simplifies the method selection and model construction process.       
Different Stability:        
If the statistical properties of the time series (such as mean and variance) change over time, the model's performance will be inconsistent across different time periods, reducing the reliability of predictions. Stationary time series have constant statistical properties, ensuring consistent predictive performance and making the model more reliable.        
Different Accuracy:      
Predicting non-stationary data is more difficult and less accurate, as the model may fail to capture the true patterns in the data. Stationary time series have constant mean and variance, allowing for more accurate predictions based on historical data. The model can better capture data patterns, providing more accurate forecasts.       
Then we may want to visually explore patterns of autocorrelation (previous values predict future ones) and cross-correlation (correlation across channels over time) using `forecast::ggAcf` function.      
The ACF plot displays the cross- and auto-correlation values for different lags (i.e., time delayed versions of each electrode's voltage timeseries) in the dataset.       
It helps identify any significant correlations between channels and observations at different time points.        
Positive autocorrelation indicates that the increase in voltage observed in a given time-interval leads to a proportionate increase in the lagged time interval as well.    
Negative autocorrelation indicates the opposite!        
What do the results of these tests tell us?      
The ADF tests show that all the time series data from the electrodes are stationary (with p-values less than 0.01). This means that the statistical properties of these EEG signals remain constant over the observation period.**


```{r correlation}
forecast::ggAcf(eeg_train %>% dplyr::select(-ds))
```



**7** Do any fields show signs of strong autocorrelation (diagonal plots)? Do any pairs of fields show signs of cross-correlation? Provide examples.      
**Autocorrelation: F7, FC5, O1, O2, T8, FC6, T4, EyeDetectation.        
Cross-correlation: FC5 & F7, F7 & FC5, T8 & FC6, T8 & F4, FC6 & F4 **

#### Frequency-Space 

We can also explore the data in frequency space by using a Fast Fourier Transform.  
After the FFT we can summarise the distributions of frequencies by their density across the power spectrum.
This will let us see if there any obvious patterns related to eye status in the overall frequency distributions.

```{r fft_open}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 0) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Open")
```

```{r fft_closed}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 1) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Closed")
```




**8** Do you see any differences between the power spectral densities for the two eye states? If so, describe them.        
**Consistency in Frequencies: The closed-eye state shows consistent higher power in specific frequency bands across many channels, which implies that the brain activity is more synchronized or stable during this state.      
Higher Power Bands: In the PSD plot for the closed-eye state, there are darker bands indicating higher power levels in certain frequency ranges compared to the open-eye state. This suggests that when the eyes are closed, there is more power concentrated in specific frequency bands.       
Uniformity Across Channels: When the eyes are closed, the power distribution appears more uniform across different channels, indicating synchronized activity across the EEG sensors. In contrast, the open-eye state shows more variation and less intense power across channels.**


#### Independent Component Analysis

We may also wish to explore whether there are multiple sources of neuronal activity being picked up by the sensors.  
This can be achieved using a process known as independent component analysis (ICA) which decorrelates the channels and identifies the primary sources of signal within the decorrelated matrix.

```{r ica, warning=FALSE}
ica <- eegkit::eegica(eeg_train %>% dplyr::select(-eyeDetection, -ds), nc=3, method='fast', type='time')
mix <- dplyr::as_tibble(ica$M)
mix$eyeDetection <- eeg_train$eyeDetection
mix$ds <- eeg_train$ds

mix_melt <- reshape2::melt(mix, id.vars=c("eyeDetection", "ds"), variable.name = "Independent Component", value.name = "M")


ggplot2::ggplot(mix_melt, ggplot2::aes(x=ds, y=M, color=`Independent Component`)) + 
  ggplot2::geom_line() + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(mix_melt, eyeDetection==1), alpha=0.005) +
  ggplot2::scale_y_log10()
```



**9** Does this suggest eye opening relates to an independent component of activity across the electrodes?         
**The plot shows that the V1 component has noticeable changes when the eyes are open, as marked by the vertical lines. These spikes and variations in V1 align with the eye-opening periods, suggesting a connection. It indicates that eye opening likely affects the V1 independent component of the EEG signals, showing distinct changes in its activity during these times.**


### Eye Opening Prediction

Now that we've explored the data let's use a simple model to see how well we can predict eye status from the EEGs:

```{r xgboost}
# Convert datasets to matrices
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

# Build the xgboost model
model <- xgboost(data = eeg_train_matrix, 
                 label = eeg_train_labels,
                 nrounds = 100,
                 max_depth = 4,
                 eta = 0.1,
                 objective = "binary:logistic")

print(model)
```



**10** Using the `caret` library (or any other library/model type you want such as a naive Bayes) fit another model to predict eye opening.      
**Coding shown as below:**
```{r model2}
# set up the data frames  
eeg_train_df <- dplyr::select(eeg_train, -eyeDetection, -ds)
eeg_train_df$eyeDetection <- as.factor(eeg_train$eyeDetection)

eeg_validate_df <- dplyr::select(eeg_validate, -eyeDetection, -ds)
eeg_validate_df$eyeDetection <- as.factor(eeg_validate$eyeDetection)

# Set up training control
train_control <- trainControl(method="cv", number=10)

# Train logistic regression model
logistic_model <- train(eyeDetection ~ ., data=eeg_train_df, method="glm", family=binomial(), trControl=train_control)

# Resutls
print(logistic_model)

# Predictions
predictions <- predict(logistic_model, newdata=eeg_validate_df)

# Results of Predictions
confusionMatrix(predictions, eeg_validate_df$eyeDetection)
```


**11** Using the best performing of the two models (on the validation dataset) calculate and report the test performance (filling in the code below):      
**Coding as shown as below:**
```{r test}
# set up the data frames  
eeg_test_df <- dplyr::select(eeg_test, -eyeDetection, -ds)
eeg_test_df$eyeDetection <- as.factor(eeg_test$eyeDetection)

# Predictions
test_predictions <- predict(logistic_model, newdata=eeg_test_df)

# Confusion matrix on the test set
test_confusion_matrix <- caret::confusionMatrix(test_predictions, eeg_test_df$eyeDetection)
print(test_confusion_matrix)
```

**12** Describe 2 possible alternative modeling approaches for prediction of eye opening from EEGs we discussed in the lecture but haven't explored in this notebook.       
**Wavelet Transform-Based Models:    
Wavelet transforms decompose EEG signals into both time and frequency domains, capturing dynamic changes in frequency content over time. This is useful for EEGs because brain activity can change rapidly. We can use the features from wavelet transforms as inputs to machine learning models like CNNs to predict eye opening. This approach helps capture the complex, transient patterns in EEG data.     
Hidden Markov Models (HMMs):      
HMMs are great for modeling sequences where we think there's some hidden state causing the observations we see. For EEGs, we can use HMMs to represent different brain activity states that result in the EEG patterns. By training an HMM on the EEG data, we can capture how these hidden states change over time, which helps in predicting eye opening events based on the EEG signals.**


**13** What are 2 R libraries you could use to implement these approaches? (note: you don't actually have to implement them though!)      
**For Wavelet Transform-Based Models: library(wavelets).     
For Hidden Markov Models (HMMs): library(depmixS4)**


## Optional

**14** (Optional) As this is the last practical of the course - let me know how you would change future offerings of this course. This will not impact your marks!      

- What worked and didn’t work for you (e.g., in terms of the practicals, tutorials, and lectures)?         
**What worked for me:     
Almost everything is extremely useful. especially the R practice classes, (even down to the details of GitHub), is invaluable. It gradually turned me into an R user (I was a Stata user before). The Data Science and ML model parts provided me with a lot of professional knowledge, which I believe will enhance my future research capabilities.
What makes me stressful:      
I can't say anything is completely useless, but the difficulty of the R practice courses escalated very quickly (but i am happy with what I learned). I think this is mainly because it is a six-week course with a lot of professional medical content. Additionally, the health-related content added to my stress as the course progressed. First, I lacked a foundational knowledge of Health and ML, and second, the specialized terminology posed a challenge for an international student. Sometimes, not understanding certain medical and ML terminology in class in a timely manner led to confusion and struggles with the subsequent content.**

- Was learning how to run the practicals on your own machines instead of a clean server that will disappear after the course worth the technical challenges?      
**No, on the contrary, I am very happy that this course allowed me to use my own machine instead of a clean server to learn R. Our own machines are what we will use for research in the future. I cannot always rely on the pre-configured machines provided by the instructors. That way, it would be hard to grow.**

- What would you add or remove from the course?       
**I wouldn't suggest to remove any part of the course. I am thinking if there could be a member confirmation step (online or in-class) before or during the grouping for the literature review presentation, it would help reduce the unexpected pressure of "missing teammates" for the first 1 or 2 groups of students.        
Additionally, I have no objections to random grouping; in fact, I think it's fantastic. For a student like me who is not from the CS department, it was a valuable opportunity to meet friends and integrate into the class.**

- What was the main thing you will take away from this course?      
**How to use R, including how to use popular platforms like GitHub.         
ML models. I believe this will help me in the future within the field of economics.       
Experience in conducting Health Data Science, which broadens the possibilities for future research in health economics.        
Thank you Prof.Finlay and David. I like this course, and thank you for respect student's opinions.**